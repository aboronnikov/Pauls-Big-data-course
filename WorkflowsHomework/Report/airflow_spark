*** Reading local file: /root/airflow/logs/pavel4/run_spark/2019-01-29T18:38:17.155086+00:00/2.log
[2019-01-29 18:52:21,098] {models.py:1359} INFO - Dependencies all met for <TaskInstance: pavel4.run_spark 2019-01-29T18:38:17.155086+00:00 [queued]>
[2019-01-29 18:52:21,100] {models.py:1359} INFO - Dependencies all met for <TaskInstance: pavel4.run_spark 2019-01-29T18:38:17.155086+00:00 [queued]>
[2019-01-29 18:52:21,101] {models.py:1571} INFO - 
--------------------------------------------------------------------------------
Starting attempt 2 of 2
--------------------------------------------------------------------------------

[2019-01-29 18:52:21,114] {models.py:1593} INFO - Executing <Task(BashOperator): run_spark> on 2019-01-29T18:38:17.155086+00:00
[2019-01-29 18:52:21,115] {base_task_runner.py:118} INFO - Running: ['bash', '-c', 'airflow run pavel4 run_spark 2019-01-29T18:38:17.155086+00:00 --job_id 250 --raw -sd DAGS_FOLDER/example_dags/pavel4.py --cfg_path /tmp/tmp36q2ip4a']
[2019-01-29 18:52:22,156] {base_task_runner.py:101} INFO - Job 250: Subtask run_spark [2019-01-29 18:52:22,154] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-01-29 18:52:22,423] {base_task_runner.py:101} INFO - Job 250: Subtask run_spark [2019-01-29 18:52:22,421] {models.py:273} INFO - Filling up the DagBag from /root/airflow/dags/example_dags/pavel4.py
[2019-01-29 18:52:23,692] {base_task_runner.py:101} INFO - Job 250: Subtask run_spark [2019-01-29 18:52:23,691] {cli.py:520} INFO - Running <TaskInstance: pavel4.run_spark 2019-01-29T18:38:17.155086+00:00 [running]> on host ecsc00a02a05.epam.com
[2019-01-29 18:52:23,706] {bash_operator.py:77} INFO - Tmp dir root location: 
 /tmp
[2019-01-29 18:52:23,706] {bash_operator.py:86} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=pavel4
AIRFLOW_CTX_TASK_ID=run_spark
AIRFLOW_CTX_EXECUTION_DATE=2019-01-29T18:38:17.155086+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2019-01-29T18:38:17.155086+00:00
[2019-01-29 18:52:23,707] {bash_operator.py:100} INFO - Temporary script location: /tmp/airflowtmpdo7s_0ya/run_sparknsf8f9tv
[2019-01-29 18:52:23,707] {bash_operator.py:110} INFO - Running command: spark2-submit --class test.Main --master yarn-client hdfs:///user/pavel_orekhov/sparkTest.jar hdfs:///user/pavel_orekhov/data1.txt hdfs:///user/pavel_orekhov/output-data
[2019-01-29 18:52:23,718] {bash_operator.py:119} INFO - Output:
[2019-01-29 18:52:25,415] {bash_operator.py:123} INFO - Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
[2019-01-29 18:52:27,641] {bash_operator.py:123} INFO - Downloading hdfs:///user/pavel_orekhov/sparkTest.jar to /tmp/tmp573464650982618587/user/pavel_orekhov/sparkTest.jar.
[2019-01-29 18:52:28,717] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SparkContext: Running Spark version 2.2.0.cloudera1
[2019-01-29 18:52:28,821] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SparkContext: Submitted application: sparkTestApp
[2019-01-29 18:52:28,860] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SecurityManager: Changing view acls to: root
[2019-01-29 18:52:28,872] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SecurityManager: Changing modify acls to: root
[2019-01-29 18:52:28,872] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SecurityManager: Changing view acls groups to:
[2019-01-29 18:52:28,872] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SecurityManager: Changing modify acls groups to:
[2019-01-29 18:52:28,872] {bash_operator.py:123} INFO - 19/01/29 18:52:28 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
[2019-01-29 18:52:29,251] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO util.Utils: Successfully started service 'sparkDriver' on port 41707.
[2019-01-29 18:52:29,281] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO spark.SparkEnv: Registering MapOutputTracker
[2019-01-29 18:52:29,318] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO spark.SparkEnv: Registering BlockManagerMaster
[2019-01-29 18:52:29,330] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2019-01-29 18:52:29,330] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2019-01-29 18:52:29,354] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-0124de36-3043-4475-8c8b-8d29e32e4b6c
[2019-01-29 18:52:29,397] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB
[2019-01-29 18:52:29,602] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO spark.SparkEnv: Registering OutputCommitCoordinator
[2019-01-29 18:52:29,728] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO util.log: Logging initialized @5586ms
[2019-01-29 18:52:29,821] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO server.Server: jetty-9.3.z-SNAPSHOT
[2019-01-29 18:52:29,853] {bash_operator.py:123} INFO - 19/01/29 18:52:29 INFO server.Server: Started @5714ms
[2019-01-29 18:52:30,007] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO server.AbstractConnector: Started ServerConnector@204e90f7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[2019-01-29 18:52:30,007] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
[2019-01-29 18:52:30,078] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4e6f2bb5{/jobs,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,079] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27a2a089{/jobs/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,085] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@706eab5d{/jobs/job,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,085] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3f9270ed{/jobs/job/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,085] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5ac6c4f2{/stages,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,085] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@61f39bb{/stages/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,092] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4893b344{/stages/stage,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,092] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2d0ecb24{/stages/stage/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,092] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3bfc6a5e{/stages/pool,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,092] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@abff8b7{/stages/pool/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,099] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@350a94ce{/storage,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,099] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b0fc838{/storage/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,099] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62db0521{/storage/rdd,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,099] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6ef1a1b9{/storage/rdd/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,100] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65753040{/environment,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,106] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4acb2510{/environment/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,117] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@37d871c2{/executors,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,118] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@285f38f6{/executors/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,118] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3ab6678b{/executors/threadDump,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,118] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b59501e{/executors/threadDump/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,136] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4eed2acf{/static,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,136] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6014a9ba{/,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,136] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@77d680e6{/api,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,137] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@cbc8d0f{/jobs/job/kill,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,137] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c1f6d57{/stages/stage/kill,null,AVAILABLE,@Spark}
[2019-01-29 18:52:30,145] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.6.195.165:4040
[2019-01-29 18:52:30,253] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO spark.SparkContext: Added JAR file:/tmp/tmp573464650982618587/user/pavel_orekhov/sparkTest.jar at spark://10.6.195.165:41707/jars/sparkTest.jar with timestamp 1548787950248
[2019-01-29 18:52:30,676] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
[2019-01-29 18:52:30,902] {bash_operator.py:123} INFO - 19/01/29 18:52:30 INFO client.RMProxy: Connecting to ResourceManager at ecsc00a022c6.epam.com/10.6.218.24:8032
[2019-01-29 18:52:31,140] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Requesting a new application from cluster with 5 NodeManagers
[2019-01-29 18:52:31,180] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (2048 MB per container)
[2019-01-29 18:52:31,180] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
[2019-01-29 18:52:31,180] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Setting up container launch context for our AM
[2019-01-29 18:52:31,180] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Setting up the launch environment for our AM container
[2019-01-29 18:52:31,194] {bash_operator.py:123} INFO - 19/01/29 18:52:31 INFO yarn.Client: Preparing resources for our AM container
[2019-01-29 18:52:32,646] {bash_operator.py:123} INFO - 19/01/29 18:52:32 INFO yarn.Client: Uploading resource file:/tmp/spark-d1a99f6c-04af-4a42-ba89-e790a9f6ab42/__spark_conf__8675803449436679980.zip -> hdfs://ecsc00a022c6.epam.com:8020/user/root/.sparkStaging/application_1548787727862_0006/__spark_conf__.zip
[2019-01-29 18:52:33,099] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO spark.SecurityManager: Changing view acls to: root
[2019-01-29 18:52:33,100] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO spark.SecurityManager: Changing modify acls to: root
[2019-01-29 18:52:33,100] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO spark.SecurityManager: Changing view acls groups to:
[2019-01-29 18:52:33,100] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO spark.SecurityManager: Changing modify acls groups to:
[2019-01-29 18:52:33,100] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
[2019-01-29 18:52:33,113] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO yarn.Client: Submitting application application_1548787727862_0006 to ResourceManager
[2019-01-29 18:52:33,189] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO impl.YarnClientImpl: Submitted application application_1548787727862_0006
[2019-01-29 18:52:33,192] {bash_operator.py:123} INFO - 19/01/29 18:52:33 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1548787727862_0006 and attemptId None
[2019-01-29 18:52:34,204] {bash_operator.py:123} INFO - 19/01/29 18:52:34 INFO yarn.Client: Application report for application_1548787727862_0006 (state: ACCEPTED)
[2019-01-29 18:52:34,207] {bash_operator.py:123} INFO - 19/01/29 18:52:34 INFO yarn.Client:
[2019-01-29 18:52:34,207] {bash_operator.py:123} INFO - 	 client token: N/A
[2019-01-29 18:52:34,207] {bash_operator.py:123} INFO - 	 diagnostics: N/A
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 ApplicationMaster host: N/A
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 ApplicationMaster RPC port: -1
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 queue: default
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 start time: 1548787953152
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 final status: UNDEFINED
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 tracking URL: http://ecsc00a022c6.epam.com:8088/proxy/application_1548787727862_0006/
[2019-01-29 18:52:34,208] {bash_operator.py:123} INFO - 	 user: root
[2019-01-29 18:52:35,219] {bash_operator.py:123} INFO - 19/01/29 18:52:35 INFO yarn.Client: Application report for application_1548787727862_0006 (state: ACCEPTED)
[2019-01-29 18:52:36,226] {bash_operator.py:123} INFO - 19/01/29 18:52:36 INFO yarn.Client: Application report for application_1548787727862_0006 (state: ACCEPTED)
[2019-01-29 18:52:36,538] {bash_operator.py:123} INFO - 19/01/29 18:52:36 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
[2019-01-29 18:52:36,547] {bash_operator.py:123} INFO - 19/01/29 18:52:36 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ecsc00a022c6.epam.com, PROXY_URI_BASES -> http://ecsc00a022c6.epam.com:8088/proxy/application_1548787727862_0006), /proxy/application_1548787727862_0006
[2019-01-29 18:52:36,547] {bash_operator.py:123} INFO - 19/01/29 18:52:36 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
[2019-01-29 18:52:37,230] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO yarn.Client: Application report for application_1548787727862_0006 (state: RUNNING)
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO yarn.Client:
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 client token: N/A
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 diagnostics: N/A
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 ApplicationMaster host: 10.6.218.24
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 ApplicationMaster RPC port: 0
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 queue: default
[2019-01-29 18:52:37,231] {bash_operator.py:123} INFO - 	 start time: 1548787953152
[2019-01-29 18:52:37,232] {bash_operator.py:123} INFO - 	 final status: UNDEFINED
[2019-01-29 18:52:37,232] {bash_operator.py:123} INFO - 	 tracking URL: http://ecsc00a022c6.epam.com:8088/proxy/application_1548787727862_0006/
[2019-01-29 18:52:37,232] {bash_operator.py:123} INFO - 	 user: root
[2019-01-29 18:52:37,244] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO cluster.YarnClientSchedulerBackend: Application application_1548787727862_0006 has started running.
[2019-01-29 18:52:37,255] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42664.
[2019-01-29 18:52:37,255] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO netty.NettyBlockTransferService: Server created on 10.6.195.165:42664
[2019-01-29 18:52:37,255] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2019-01-29 18:52:37,255] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.6.195.165, 42664, None)
[2019-01-29 18:52:37,266] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.6.195.165:42664 with 366.3 MB RAM, BlockManagerId(driver, 10.6.195.165, 42664, None)
[2019-01-29 18:52:37,277] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.6.195.165, 42664, None)
[2019-01-29 18:52:37,277] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManager: external shuffle service port = 7337
[2019-01-29 18:52:37,277] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.6.195.165, 42664, None)
[2019-01-29 18:52:37,507] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@19662208{/metrics/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:37,684] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO scheduler.EventLoggingListener: Logging events to hdfs://ecsc00a022c6.epam.com:8020/user/spark/spark2ApplicationHistory/application_1548787727862_0006
[2019-01-29 18:52:37,689] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO util.Utils: Using initial executors = 0, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
[2019-01-29 18:52:37,762] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
[2019-01-29 18:52:37,892] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO internal.SharedState: loading hive config file: file:/etc/spark2/conf.cloudera.spark2_on_yarn/yarn-conf/hive-site.xml
[2019-01-29 18:52:37,936] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO internal.SharedState: spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
[2019-01-29 18:52:37,936] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO internal.SharedState: Warehouse path is '/user/hive/warehouse'.
[2019-01-29 18:52:37,957] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@66020d69{/SQL,null,AVAILABLE,@Spark}
[2019-01-29 18:52:37,957] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6b832551{/SQL/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:37,958] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@55421b8d{/SQL/execution,null,AVAILABLE,@Spark}
[2019-01-29 18:52:37,958] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6615237{/SQL/execution/json,null,AVAILABLE,@Spark}
[2019-01-29 18:52:37,958] {bash_operator.py:123} INFO - 19/01/29 18:52:37 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b3cbe6e{/static/sql,null,AVAILABLE,@Spark}
[2019-01-29 18:52:39,041] {bash_operator.py:123} INFO - 19/01/29 18:52:39 INFO hive.HiveUtils: Initializing HiveMetastoreConnection version 1.1.0 using file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-logging-1.1.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-exec-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-exec.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-jdbc-1.1.0-cdh5.12.2-standalone.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-jdbc-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-jdbc-standalone.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-jdbc.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-metastore-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-metastore.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-serde-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-serde.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-service-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-service.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/libfb303-0.9.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/libthrift-0.9.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/log4j-1.2.16.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-client.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-hadoop-compat.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-hadoop2-compat.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-protocol.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-server.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/htrace-core.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/ST4-4.0.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/accumulo-core-1.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/accumulo-fate-1.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/accumulo-start-1.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/accumulo-trace-1.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/activation-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/ant-1.9.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/ant-launcher-1.9.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/antlr-2.7.7.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/antlr-runtime-3.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/apache-log4j-extras-1.2.17.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/asm-3.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/asm-commons-3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/asm-tree-3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/avro.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/bonecp-0.8.0.RELEASE.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/calcite-avatica-1.0.0-incubating.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/calcite-core-1.0.0-incubating.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/calcite-linq4j-1.0.0-incubating.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-beanutils-1.9.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-beanutils-core-1.8.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-cli-1.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-codec-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-collections-3.2.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-compiler-2.7.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-compress-1.4.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-configuration-1.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-dbcp-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-digester-1.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-el-1.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-httpclient-3.0.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-io-2.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-lang-2.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-lang3-3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-math-2.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-pool-1.5.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/commons-vfs2-2.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/curator-client-2.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/curator-framework-2.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/curator-recipes-2.6.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/datanucleus-api-jdo-3.2.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/datanucleus-core-3.2.10.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/datanucleus-rdbms-3.2.9.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/derby-10.11.1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/eigenbase-properties-1.1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/findbugs-annotations-1.3.9-1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/groovy-all-2.4.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/gson-2.2.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/guava-14.0.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hamcrest-core-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hbase-annotations.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/high-scale-lib-1.1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-accumulo-handler-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-accumulo-handler.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-ant-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-ant.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-beeline-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-beeline.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-cli-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-cli.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-common-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-contrib-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-contrib.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-hbase-handler-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-hbase-handler.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-hwi-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-hwi.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-0.23-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-0.23.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-common-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-scheduler-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims-scheduler.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-shims.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-testutils.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jamon-runtime-2.3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jackson-xc-1.9.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jackson-databind-2.2.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jackson-annotations-2.2.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/zookeeper.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/velocity-1.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/snappy-java-1.0.4.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/plexus-utils-1.5.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/paranamer-2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/oro-2.0.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/httpclient-4.2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/xz-1.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/tempus-fugit-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/super-csv-2.2.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/stax-api-1.0.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/servlet-api-2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/opencsv-2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/metrics-jvm-3.0.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/metrics-json-3.0.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/metrics-core-3.0.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/maven-scm-provider-svnexe-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/maven-scm-provider-svn-commons-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/maven-scm-api-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/mail-1.4.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/logredactor-1.0.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/junit-4.11.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jta-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jsr305-3.0.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jsp-api-2.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jpam-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/joda-time-1.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jline-2.12.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jetty-all-server-7.6.0.v20120127.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jetty-all-7.6.0.v20120127.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jersey-servlet-1.14.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jersey-server-1.14.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jdo-api-3.0.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jcommander-1.32.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jasper-runtime-5.5.23.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jasper-compiler-5.5.23.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/janino-2.7.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jackson-jaxrs-1.9.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/jackson-core-2.2.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/ivy-2.0.0-rc2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/parquet-hadoop-bundle.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/stringtemplate-3.2.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/regexp-1.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/httpcore-4.2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/../hive/lib/hive-testutils-1.1.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/activation-1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/activation.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/apacheds-i18n-2.0.0-M15.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/apacheds-i18n.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/apacheds-kerberos-codec-2.0.0-M15.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/apacheds-kerberos-codec.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/api-asn1-api-1.0.0-M20.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/api-asn1-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/api-util-1.0.0-M20.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/api-util.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/avro.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/aws-java-sdk-bundle-1.11.134.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/aws-java-sdk-bundle.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/azure-data-lake-store-sdk-2.1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/azure-data-lake-store-sdk.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-beanutils-1.9.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-beanutils-core-1.8.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-beanutils-core.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-beanutils.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-cli-1.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-cli.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-codec-1.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-codec.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-collections-3.2.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-collections.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-compress-1.4.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-compress.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-configuration-1.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-configuration.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-digester-1.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-digester.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-httpclient-3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-httpclient.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-io-2.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-io.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-lang-2.6.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-lang.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-logging-1.1.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-logging.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-math3-3.1.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-math3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-net-3.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/commons-net.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-client-2.7.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-client.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-framework-2.7.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-framework.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-recipes-2.7.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/curator-recipes.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/gson-2.2.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/gson.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/guava-11.0.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/guava.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-annotations-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-annotations.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-auth-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-auth.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-aws-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-aws.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-azure-datalake-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-azure-datalake.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-common-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-hdfs-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-hdfs.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-app-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-app.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-common-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-core-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-core.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-jobclient.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-shuffle-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-mapreduce-client-shuffle.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-api-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-client-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-client.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-common-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-server-common-2.6.0-cdh5.12.2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/hadoop-yarn-server-common.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/htrace-core4-4.0.1-incubating.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/htrace-core4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/httpclient-4.2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/httpclient.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/httpcore-4.2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/httpcore.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-annotations-2.2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-annotations.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-core-2.2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-core.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-databind-2.2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-databind.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-jaxrs-1.8.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-jaxrs.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-xc-1.8.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jackson-xc.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/zookeeper.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xz.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xz-1.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xmlenc.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xmlenc-0.52.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xml-apis.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xml-apis-1.3.04.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xercesImpl.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/xercesImpl-2.9.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/stax-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/stax-api-1.0-2.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/snappy-java.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/snappy-java-1.0.4.1.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/slf4j-log4j12.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/slf4j-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/slf4j-api-1.7.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/servlet-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/servlet-api-2.5.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/protobuf-java.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/protobuf-java-2.5.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/paranamer.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/paranamer-2.3.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/netty.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/netty-3.10.5.Final.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/log4j.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/log4j-1.2.17.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/leveldbjni-all.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/leveldbjni-all-1.8.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jsr305.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jsr305-3.0.0.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jetty-util.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jetty-util-6.1.26.cloudera.4.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jersey-core.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jersey-core-1.9.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jersey-client.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jersey-client-1.9.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jaxb-api.jar:file:/opt/cloudera/parcels/CDH-5.12.2-1.cdh5.12.2.p0.4/lib/hadoop/client/jaxb-api-2.2.2.jar
[2019-01-29 18:52:40,266] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO session.SessionState: Created local directory: /tmp/62d149a1-e717-497e-a7df-c8476ca2b7eb_resources
[2019-01-29 18:52:40,274] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO session.SessionState: Created HDFS directory: /tmp/hive/root/62d149a1-e717-497e-a7df-c8476ca2b7eb
[2019-01-29 18:52:40,283] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO session.SessionState: Created local directory: /tmp/root/62d149a1-e717-497e-a7df-c8476ca2b7eb
[2019-01-29 18:52:40,290] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO session.SessionState: Created HDFS directory: /tmp/hive/root/62d149a1-e717-497e-a7df-c8476ca2b7eb/_tmp_space.db
[2019-01-29 18:52:40,297] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
[2019-01-29 18:52:40,297] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO client.HiveClientImpl: Warehouse location for Hive client (version 1.1.0) is /user/hive/warehouse
[2019-01-29 18:52:40,660] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO hive.metastore: Trying to connect to metastore with URI thrift://ecsc00a022c7.epam.com:9083
[2019-01-29 18:52:40,711] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO hive.metastore: Opened a connection to metastore, current connections: 1
[2019-01-29 18:52:40,729] {bash_operator.py:123} INFO - 19/01/29 18:52:40 INFO hive.metastore: Connected to metastore.
[2019-01-29 18:52:41,258] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO session.SessionState: Created local directory: /tmp/f9042536-912a-44e9-acaf-d1e60b4dbcf6_resources
[2019-01-29 18:52:41,264] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO session.SessionState: Created HDFS directory: /tmp/hive/root/f9042536-912a-44e9-acaf-d1e60b4dbcf6
[2019-01-29 18:52:41,267] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO session.SessionState: Created local directory: /tmp/root/f9042536-912a-44e9-acaf-d1e60b4dbcf6
[2019-01-29 18:52:41,282] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO session.SessionState: Created HDFS directory: /tmp/hive/root/f9042536-912a-44e9-acaf-d1e60b4dbcf6/_tmp_space.db
[2019-01-29 18:52:41,282] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO session.SessionState: No Tez session required at this point. hive.execution.engine=mr.
[2019-01-29 18:52:41,282] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO client.HiveClientImpl: Warehouse location for Hive client (version 1.1.0) is /user/hive/warehouse
[2019-01-29 18:52:41,329] {bash_operator.py:123} INFO - 19/01/29 18:52:41 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
[2019-01-29 18:52:42,664] {bash_operator.py:123} INFO - 19/01/29 18:52:42 INFO datasources.FileSourceStrategy: Pruning directories with:
[2019-01-29 18:52:42,665] {bash_operator.py:123} INFO - 19/01/29 18:52:42 INFO datasources.FileSourceStrategy: Post-Scan Filters: (length(trim(value#0)) > 0)
[2019-01-29 18:52:42,665] {bash_operator.py:123} INFO - 19/01/29 18:52:42 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
[2019-01-29 18:52:42,683] {bash_operator.py:123} INFO - 19/01/29 18:52:42 INFO execution.FileSourceScanExec: Pushed Filters:
[2019-01-29 18:52:43,348] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO codegen.CodeGenerator: Code generated in 247.737648 ms
[2019-01-29 18:52:43,416] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.7 KB, free 366.0 MB)
[2019-01-29 18:52:43,651] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.4 KB, free 366.0 MB)
[2019-01-29 18:52:43,656] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.6.195.165:42664 (size: 29.4 KB, free: 366.3 MB)
[2019-01-29 18:52:43,664] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO spark.SparkContext: Created broadcast 0 from csv at Main.scala:21
[2019-01-29 18:52:43,683] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2019-01-29 18:52:43,912] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO spark.SparkContext: Starting job: csv at Main.scala:21
[2019-01-29 18:52:43,937] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO scheduler.DAGScheduler: Got job 0 (csv at Main.scala:21) with 1 output partitions
[2019-01-29 18:52:43,937] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (csv at Main.scala:21)
[2019-01-29 18:52:43,938] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO scheduler.DAGScheduler: Parents of final stage: List()
[2019-01-29 18:52:43,943] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO scheduler.DAGScheduler: Missing parents: List()
[2019-01-29 18:52:43,951] {bash_operator.py:123} INFO - 19/01/29 18:52:43 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at csv at Main.scala:21), which has no missing parents
[2019-01-29 18:52:44,045] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.2 KB, free 366.0 MB)
[2019-01-29 18:52:44,070] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 365.9 MB)
[2019-01-29 18:52:44,075] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.6.195.165:42664 (size: 4.3 KB, free: 366.3 MB)
[2019-01-29 18:52:44,078] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
[2019-01-29 18:52:44,093] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at csv at Main.scala:21) (first 15 tasks are for partitions Vector(0))
[2019-01-29 18:52:44,099] {bash_operator.py:123} INFO - 19/01/29 18:52:44 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks
[2019-01-29 18:52:45,204] {bash_operator.py:123} INFO - 19/01/29 18:52:45 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 1)
[2019-01-29 18:52:49,850] {bash_operator.py:123} INFO - 19/01/29 18:52:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.6.195.165:38918) with ID 1
[2019-01-29 18:52:49,910] {bash_operator.py:123} INFO - 19/01/29 18:52:49 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, ecsc00a02a05.epam.com, executor 1, partition 0, NODE_LOCAL, 5310 bytes)
[2019-01-29 18:52:49,914] {bash_operator.py:123} INFO - 19/01/29 18:52:49 INFO spark.ExecutorAllocationManager: New executor 1 has registered (new total is 1)
[2019-01-29 18:52:49,978] {bash_operator.py:123} INFO - 19/01/29 18:52:49 INFO storage.BlockManagerMasterEndpoint: Registering block manager ecsc00a02a05.epam.com:35322 with 366.3 MB RAM, BlockManagerId(1, ecsc00a02a05.epam.com, 35322, None)
[2019-01-29 18:52:51,720] {bash_operator.py:123} INFO - 19/01/29 18:52:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on ecsc00a02a05.epam.com:35322 (size: 4.3 KB, free: 366.3 MB)
[2019-01-29 18:52:52,774] {bash_operator.py:123} INFO - 19/01/29 18:52:52 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on ecsc00a02a05.epam.com:35322 (size: 29.4 KB, free: 366.3 MB)
[2019-01-29 18:52:54,875] {bash_operator.py:123} INFO - 19/01/29 18:52:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 4991 ms on ecsc00a02a05.epam.com (executor 1) (1/1)
[2019-01-29 18:52:54,898] {bash_operator.py:123} INFO - 19/01/29 18:52:54 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2019-01-29 18:52:54,914] {bash_operator.py:123} INFO - 19/01/29 18:52:54 INFO scheduler.DAGScheduler: ResultStage 0 (csv at Main.scala:21) finished in 10.620 s
[2019-01-29 18:52:54,945] {bash_operator.py:123} INFO - 19/01/29 18:52:54 INFO scheduler.DAGScheduler: Job 0 finished: csv at Main.scala:21, took 11.004757 s
[2019-01-29 18:52:55,380] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO codegen.CodeGenerator: Code generated in 416.064963 ms
[2019-01-29 18:52:55,440] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on ecsc00a02a05.epam.com:35322 in memory (size: 4.3 KB, free: 366.3 MB)
[2019-01-29 18:52:55,488] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.6.195.165:42664 in memory (size: 4.3 KB, free: 366.3 MB)
[2019-01-29 18:52:55,505] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Pruning directories with:
[2019-01-29 18:52:55,505] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Post-Scan Filters:
[2019-01-29 18:52:55,506] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Output Data Schema: struct<value: string>
[2019-01-29 18:52:55,506] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO execution.FileSourceScanExec: Pushed Filters:
[2019-01-29 18:52:55,515] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO codegen.CodeGenerator: Code generated in 12.331602 ms
[2019-01-29 18:52:55,522] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 317.7 KB, free 365.7 MB)
[2019-01-29 18:52:55,549] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.4 KB, free 365.6 MB)
[2019-01-29 18:52:55,550] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.6.195.165:42664 (size: 29.4 KB, free: 366.2 MB)
[2019-01-29 18:52:55,554] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO spark.SparkContext: Created broadcast 2 from csv at Main.scala:21
[2019-01-29 18:52:55,554] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2019-01-29 18:52:55,809] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Pruning directories with:
[2019-01-29 18:52:55,809] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Post-Scan Filters:
[2019-01-29 18:52:55,809] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO datasources.FileSourceStrategy: Output Data Schema: struct<_c1: string>
[2019-01-29 18:52:55,809] {bash_operator.py:123} INFO - 19/01/29 18:52:55 INFO execution.FileSourceScanExec: Pushed Filters:
[2019-01-29 18:52:56,071] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO avro.DefaultSource: compressing Avro output using Snappy
[2019-01-29 18:52:56,072] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO Configuration.deprecation: mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress
[2019-01-29 18:52:56,099] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
[2019-01-29 18:52:56,100] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2019-01-29 18:52:56,104] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2019-01-29 18:52:56,224] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO codegen.CodeGenerator: Code generated in 61.242126 ms
[2019-01-29 18:52:56,372] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO codegen.CodeGenerator: Code generated in 102.003652 ms
[2019-01-29 18:52:56,375] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 317.7 KB, free 365.3 MB)
[2019-01-29 18:52:56,393] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.4 KB, free 365.3 MB)
[2019-01-29 18:52:56,394] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.6.195.165:42664 (size: 29.4 KB, free: 366.2 MB)
[2019-01-29 18:52:56,404] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO spark.SparkContext: Created broadcast 3 from save at package.scala:26
[2019-01-29 18:52:56,404] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2019-01-29 18:52:56,526] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO spark.SparkContext: Starting job: save at package.scala:26
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Registering RDD 10 (save at package.scala:26)
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Got job 1 (save at package.scala:26) with 200 output partitions
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (save at package.scala:26)
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)
[2019-01-29 18:52:56,534] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at save at package.scala:26), which has no missing parents
[2019-01-29 18:52:56,544] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.1 KB, free 365.3 MB)
[2019-01-29 18:52:56,550] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 12.2 KB, free 365.2 MB)
[2019-01-29 18:52:56,553] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.6.195.165:42664 (size: 12.2 KB, free: 366.2 MB)
[2019-01-29 18:52:56,556] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
[2019-01-29 18:52:56,557] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at save at package.scala:26) (first 15 tasks are for partitions Vector(0))
[2019-01-29 18:52:56,557] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks
[2019-01-29 18:52:56,560] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, ecsc00a02a05.epam.com, executor 1, partition 0, NODE_LOCAL, 5299 bytes)
[2019-01-29 18:52:56,617] {bash_operator.py:123} INFO - 19/01/29 18:52:56 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on ecsc00a02a05.epam.com:35322 (size: 12.2 KB, free: 366.3 MB)
[2019-01-29 18:52:57,088] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on ecsc00a02a05.epam.com:35322 (size: 29.4 KB, free: 366.2 MB)
[2019-01-29 18:52:57,299] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 741 ms on ecsc00a02a05.epam.com (executor 1) (1/1)
[2019-01-29 18:52:57,299] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2019-01-29 18:52:57,302] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: ShuffleMapStage 1 (save at package.scala:26) finished in 0.744 s
[2019-01-29 18:52:57,304] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: looking for newly runnable stages
[2019-01-29 18:52:57,304] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: running: Set()
[2019-01-29 18:52:57,310] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 2)
[2019-01-29 18:52:57,310] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: failed: Set()
[2019-01-29 18:52:57,313] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at save at package.scala:26), which has no missing parents
[2019-01-29 18:52:57,354] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 107.5 KB, free 365.1 MB)
[2019-01-29 18:52:57,357] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 42.9 KB, free 365.1 MB)
[2019-01-29 18:52:57,358] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.6.195.165:42664 (size: 42.9 KB, free: 366.2 MB)
[2019-01-29 18:52:57,361] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
[2019-01-29 18:52:57,362] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.DAGScheduler: Submitting 200 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at save at package.scala:26) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
[2019-01-29 18:52:57,362] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO cluster.YarnScheduler: Adding task set 2.0 with 200 tasks
[2019-01-29 18:52:57,364] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 2.0 (TID 2, ecsc00a02a05.epam.com, executor 1, partition 7, NODE_LOCAL, 4737 bytes)
[2019-01-29 18:52:57,393] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on ecsc00a02a05.epam.com:35322 (size: 42.9 KB, free: 366.2 MB)
[2019-01-29 18:52:57,476] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.6.195.165:38918
[2019-01-29 18:52:57,482] {bash_operator.py:123} INFO - 19/01/29 18:52:57 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 168 bytes
[2019-01-29 18:52:58,296] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 19.0 in stage 2.0 (TID 3, ecsc00a02a05.epam.com, executor 1, partition 19, NODE_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,331] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 2.0 (TID 2) in 967 ms on ecsc00a02a05.epam.com (executor 1) (1/200)
[2019-01-29 18:52:58,351] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 2)
[2019-01-29 18:52:58,458] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 33.0 in stage 2.0 (TID 4, ecsc00a02a05.epam.com, executor 1, partition 33, NODE_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,467] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 19.0 in stage 2.0 (TID 3) in 172 ms on ecsc00a02a05.epam.com (executor 1) (2/200)
[2019-01-29 18:52:58,564] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 87.0 in stage 2.0 (TID 5, ecsc00a02a05.epam.com, executor 1, partition 87, NODE_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,574] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 33.0 in stage 2.0 (TID 4) in 116 ms on ecsc00a02a05.epam.com (executor 1) (3/200)
[2019-01-29 18:52:58,679] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, ecsc00a02a05.epam.com, executor 1, partition 0, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,680] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 87.0 in stage 2.0 (TID 5) in 115 ms on ecsc00a02a05.epam.com (executor 1) (4/200)
[2019-01-29 18:52:58,786] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, ecsc00a02a05.epam.com, executor 1, partition 1, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,787] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 114 ms on ecsc00a02a05.epam.com (executor 1) (5/200)
[2019-01-29 18:52:58,901] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8, ecsc00a02a05.epam.com, executor 1, partition 2, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:58,906] {bash_operator.py:123} INFO - 19/01/29 18:52:58 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 121 ms on ecsc00a02a05.epam.com (executor 1) (6/200)
[2019-01-29 18:52:59,065] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 9, ecsc00a02a05.epam.com, executor 1, partition 3, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,071] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 170 ms on ecsc00a02a05.epam.com (executor 1) (7/200)
[2019-01-29 18:52:59,202] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 10, ecsc00a02a05.epam.com, executor 1, partition 4, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,202] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 9) in 138 ms on ecsc00a02a05.epam.com (executor 1) (8/200)
[2019-01-29 18:52:59,320] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 2.0 (TID 11, ecsc00a02a05.epam.com, executor 1, partition 5, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,320] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 10) in 119 ms on ecsc00a02a05.epam.com (executor 1) (9/200)
[2019-01-29 18:52:59,391] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO spark.ExecutorAllocationManager: Requesting 1 new executor because tasks are backlogged (new desired total will be 3)
[2019-01-29 18:52:59,464] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 2.0 (TID 12, ecsc00a02a05.epam.com, executor 1, partition 6, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,478] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 2.0 (TID 11) in 161 ms on ecsc00a02a05.epam.com (executor 1) (10/200)
[2019-01-29 18:52:59,625] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 2.0 (TID 13, ecsc00a02a05.epam.com, executor 1, partition 8, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,637] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 2.0 (TID 12) in 170 ms on ecsc00a02a05.epam.com (executor 1) (11/200)
[2019-01-29 18:52:59,726] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 2.0 (TID 14, ecsc00a02a05.epam.com, executor 1, partition 9, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,728] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 2.0 (TID 13) in 102 ms on ecsc00a02a05.epam.com (executor 1) (12/200)
[2019-01-29 18:52:59,908] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 2.0 (TID 15, ecsc00a02a05.epam.com, executor 1, partition 10, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:52:59,910] {bash_operator.py:123} INFO - 19/01/29 18:52:59 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 2.0 (TID 14) in 184 ms on ecsc00a02a05.epam.com (executor 1) (13/200)
[2019-01-29 18:53:00,205] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 2.0 (TID 16, ecsc00a02a05.epam.com, executor 1, partition 11, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,206] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 2.0 (TID 15) in 298 ms on ecsc00a02a05.epam.com (executor 1) (14/200)
[2019-01-29 18:53:00,317] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 2.0 (TID 17, ecsc00a02a05.epam.com, executor 1, partition 12, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,317] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 2.0 (TID 16) in 119 ms on ecsc00a02a05.epam.com (executor 1) (15/200)
[2019-01-29 18:53:00,434] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO spark.ExecutorAllocationManager: Requesting 2 new executors because tasks are backlogged (new desired total will be 5)
[2019-01-29 18:53:00,502] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 2.0 (TID 18, ecsc00a02a05.epam.com, executor 1, partition 13, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,502] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 2.0 (TID 17) in 186 ms on ecsc00a02a05.epam.com (executor 1) (16/200)
[2019-01-29 18:53:00,747] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 2.0 (TID 19, ecsc00a02a05.epam.com, executor 1, partition 14, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,754] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 2.0 (TID 18) in 252 ms on ecsc00a02a05.epam.com (executor 1) (17/200)
[2019-01-29 18:53:00,846] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 2.0 (TID 20, ecsc00a02a05.epam.com, executor 1, partition 15, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,846] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 2.0 (TID 19) in 100 ms on ecsc00a02a05.epam.com (executor 1) (18/200)
[2019-01-29 18:53:00,941] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Starting task 16.0 in stage 2.0 (TID 21, ecsc00a02a05.epam.com, executor 1, partition 16, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:00,950] {bash_operator.py:123} INFO - 19/01/29 18:53:00 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 2.0 (TID 20) in 104 ms on ecsc00a02a05.epam.com (executor 1) (19/200)
[2019-01-29 18:53:01,093] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 17.0 in stage 2.0 (TID 22, ecsc00a02a05.epam.com, executor 1, partition 17, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,095] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 16.0 in stage 2.0 (TID 21) in 154 ms on ecsc00a02a05.epam.com (executor 1) (20/200)
[2019-01-29 18:53:01,216] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 18.0 in stage 2.0 (TID 23, ecsc00a02a05.epam.com, executor 1, partition 18, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,219] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 17.0 in stage 2.0 (TID 22) in 127 ms on ecsc00a02a05.epam.com (executor 1) (21/200)
[2019-01-29 18:53:01,381] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 20.0 in stage 2.0 (TID 24, ecsc00a02a05.epam.com, executor 1, partition 20, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,381] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 18.0 in stage 2.0 (TID 23) in 166 ms on ecsc00a02a05.epam.com (executor 1) (22/200)
[2019-01-29 18:53:01,465] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO spark.ExecutorAllocationManager: Requesting 4 new executors because tasks are backlogged (new desired total will be 9)
[2019-01-29 18:53:01,475] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 21.0 in stage 2.0 (TID 25, ecsc00a02a05.epam.com, executor 1, partition 21, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,475] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 20.0 in stage 2.0 (TID 24) in 93 ms on ecsc00a02a05.epam.com (executor 1) (23/200)
[2019-01-29 18:53:01,650] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 22.0 in stage 2.0 (TID 26, ecsc00a02a05.epam.com, executor 1, partition 22, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,650] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 21.0 in stage 2.0 (TID 25) in 177 ms on ecsc00a02a05.epam.com (executor 1) (24/200)
[2019-01-29 18:53:01,797] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 23.0 in stage 2.0 (TID 27, ecsc00a02a05.epam.com, executor 1, partition 23, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,799] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 22.0 in stage 2.0 (TID 26) in 152 ms on ecsc00a02a05.epam.com (executor 1) (25/200)
[2019-01-29 18:53:01,860] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.6.194.238:47762) with ID 2
[2019-01-29 18:53:01,863] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 24.0 in stage 2.0 (TID 28, ecsc00a022c7.epam.com, executor 2, partition 24, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,880] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO spark.ExecutorAllocationManager: New executor 2 has registered (new total is 2)
[2019-01-29 18:53:01,913] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Starting task 25.0 in stage 2.0 (TID 29, ecsc00a02a05.epam.com, executor 1, partition 25, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:01,913] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO storage.BlockManagerMasterEndpoint: Registering block manager ecsc00a022c7.epam.com:39556 with 366.3 MB RAM, BlockManagerId(2, ecsc00a022c7.epam.com, 39556, None)
[2019-01-29 18:53:01,914] {bash_operator.py:123} INFO - 19/01/29 18:53:01 INFO scheduler.TaskSetManager: Finished task 23.0 in stage 2.0 (TID 27) in 127 ms on ecsc00a02a05.epam.com (executor 1) (26/200)
[2019-01-29 18:53:02,053] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 26.0 in stage 2.0 (TID 30, ecsc00a02a05.epam.com, executor 1, partition 26, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,054] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 25.0 in stage 2.0 (TID 29) in 141 ms on ecsc00a02a05.epam.com (executor 1) (27/200)
[2019-01-29 18:53:02,271] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 27.0 in stage 2.0 (TID 31, ecsc00a02a05.epam.com, executor 1, partition 27, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,271] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 26.0 in stage 2.0 (TID 30) in 221 ms on ecsc00a02a05.epam.com (executor 1) (28/200)
[2019-01-29 18:53:02,511] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 28.0 in stage 2.0 (TID 32, ecsc00a02a05.epam.com, executor 1, partition 28, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,512] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 27.0 in stage 2.0 (TID 31) in 239 ms on ecsc00a02a05.epam.com (executor 1) (29/200)
[2019-01-29 18:53:02,525] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO spark.ExecutorAllocationManager: Requesting 8 new executors because tasks are backlogged (new desired total will be 17)
[2019-01-29 18:53:02,702] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 29.0 in stage 2.0 (TID 33, ecsc00a02a05.epam.com, executor 1, partition 29, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,702] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 28.0 in stage 2.0 (TID 32) in 194 ms on ecsc00a02a05.epam.com (executor 1) (30/200)
[2019-01-29 18:53:02,852] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 30.0 in stage 2.0 (TID 34, ecsc00a02a05.epam.com, executor 1, partition 30, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,852] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 29.0 in stage 2.0 (TID 33) in 152 ms on ecsc00a02a05.epam.com (executor 1) (31/200)
[2019-01-29 18:53:02,940] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Starting task 31.0 in stage 2.0 (TID 35, ecsc00a02a05.epam.com, executor 1, partition 31, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:02,940] {bash_operator.py:123} INFO - 19/01/29 18:53:02 INFO scheduler.TaskSetManager: Finished task 30.0 in stage 2.0 (TID 34) in 89 ms on ecsc00a02a05.epam.com (executor 1) (32/200)
[2019-01-29 18:53:03,067] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 32.0 in stage 2.0 (TID 36, ecsc00a02a05.epam.com, executor 1, partition 32, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,071] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Finished task 31.0 in stage 2.0 (TID 35) in 137 ms on ecsc00a02a05.epam.com (executor 1) (33/200)
[2019-01-29 18:53:03,163] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on ecsc00a022c7.epam.com:39556 (size: 42.9 KB, free: 366.3 MB)
[2019-01-29 18:53:03,182] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 34.0 in stage 2.0 (TID 37, ecsc00a02a05.epam.com, executor 1, partition 34, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,182] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Finished task 32.0 in stage 2.0 (TID 36) in 107 ms on ecsc00a02a05.epam.com (executor 1) (34/200)
[2019-01-29 18:53:03,239] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.6.195.164:51682) with ID 3
[2019-01-29 18:53:03,246] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 35.0 in stage 2.0 (TID 38, ECSC00A02A04.epam.com, executor 3, partition 35, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,250] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO spark.ExecutorAllocationManager: New executor 3 has registered (new total is 3)
[2019-01-29 18:53:03,259] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 36.0 in stage 2.0 (TID 39, ecsc00a02a05.epam.com, executor 1, partition 36, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,259] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Finished task 34.0 in stage 2.0 (TID 37) in 87 ms on ecsc00a02a05.epam.com (executor 1) (35/200)
[2019-01-29 18:53:03,304] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO storage.BlockManagerMasterEndpoint: Registering block manager ECSC00A02A04.epam.com:42348 with 366.3 MB RAM, BlockManagerId(3, ECSC00A02A04.epam.com, 42348, None)
[2019-01-29 18:53:03,544] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 37.0 in stage 2.0 (TID 40, ecsc00a02a05.epam.com, executor 1, partition 37, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,544] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Finished task 36.0 in stage 2.0 (TID 39) in 283 ms on ecsc00a02a05.epam.com (executor 1) (36/200)
[2019-01-29 18:53:03,577] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO spark.ExecutorAllocationManager: Requesting 16 new executors because tasks are backlogged (new desired total will be 33)
[2019-01-29 18:53:03,678] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.6.194.238:47762
[2019-01-29 18:53:03,880] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Starting task 38.0 in stage 2.0 (TID 41, ecsc00a02a05.epam.com, executor 1, partition 38, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:03,881] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO scheduler.TaskSetManager: Finished task 37.0 in stage 2.0 (TID 40) in 335 ms on ecsc00a02a05.epam.com (executor 1) (37/200)
[2019-01-29 18:53:03,881] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.6.219.173:41742) with ID 4
[2019-01-29 18:53:03,895] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO spark.ExecutorAllocationManager: New executor 4 has registered (new total is 4)
[2019-01-29 18:53:03,946] {bash_operator.py:123} INFO - 19/01/29 18:53:03 INFO storage.BlockManagerMasterEndpoint: Registering block manager ecsc00a02339.epam.com:35861 with 366.3 MB RAM, BlockManagerId(4, ecsc00a02339.epam.com, 35861, None)
[2019-01-29 18:53:04,002] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Starting task 39.0 in stage 2.0 (TID 42, ecsc00a02339.epam.com, executor 4, partition 39, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:04,046] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Starting task 40.0 in stage 2.0 (TID 43, ecsc00a02a05.epam.com, executor 1, partition 40, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:04,055] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Finished task 38.0 in stage 2.0 (TID 41) in 174 ms on ecsc00a02a05.epam.com (executor 1) (38/200)
[2019-01-29 18:53:04,141] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Starting task 41.0 in stage 2.0 (TID 44, ecsc00a02a05.epam.com, executor 1, partition 41, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:04,144] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Finished task 40.0 in stage 2.0 (TID 43) in 98 ms on ecsc00a02a05.epam.com (executor 1) (39/200)
[2019-01-29 18:53:04,302] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Starting task 42.0 in stage 2.0 (TID 45, ecsc00a02a05.epam.com, executor 1, partition 42, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:04,314] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Finished task 41.0 in stage 2.0 (TID 44) in 166 ms on ecsc00a02a05.epam.com (executor 1) (40/200)
[2019-01-29 18:53:04,622] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO spark.ExecutorAllocationManager: Requesting 32 new executors because tasks are backlogged (new desired total will be 65)
[2019-01-29 18:53:04,676] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on ECSC00A02A04.epam.com:42348 (size: 42.9 KB, free: 366.3 MB)
[2019-01-29 18:53:04,945] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Starting task 43.0 in stage 2.0 (TID 46, ecsc00a02a05.epam.com, executor 1, partition 43, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:04,951] {bash_operator.py:123} INFO - 19/01/29 18:53:04 INFO scheduler.TaskSetManager: Finished task 42.0 in stage 2.0 (TID 45) in 649 ms on ecsc00a02a05.epam.com (executor 1) (41/200)
[2019-01-29 18:53:05,129] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on ecsc00a02339.epam.com:35861 (size: 42.9 KB, free: 366.3 MB)
[2019-01-29 18:53:05,190] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Starting task 44.0 in stage 2.0 (TID 47, ecsc00a02a05.epam.com, executor 1, partition 44, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:05,191] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Finished task 43.0 in stage 2.0 (TID 46) in 246 ms on ecsc00a02a05.epam.com (executor 1) (42/200)
[2019-01-29 18:53:05,239] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.6.195.164:51682
[2019-01-29 18:53:05,350] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Starting task 45.0 in stage 2.0 (TID 48, ecsc00a02a05.epam.com, executor 1, partition 45, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:05,354] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Finished task 44.0 in stage 2.0 (TID 47) in 165 ms on ecsc00a02a05.epam.com (executor 1) (43/200)
[2019-01-29 18:53:05,662] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.6.219.173:41742
[2019-01-29 18:53:05,670] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO spark.ExecutorAllocationManager: Requesting 64 new executors because tasks are backlogged (new desired total will be 129)
[2019-01-29 18:53:05,871] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Starting task 46.0 in stage 2.0 (TID 49, ecsc00a022c7.epam.com, executor 2, partition 46, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:05,875] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Finished task 24.0 in stage 2.0 (TID 28) in 4014 ms on ecsc00a022c7.epam.com (executor 2) (44/200)
[2019-01-29 18:53:05,945] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Starting task 47.0 in stage 2.0 (TID 50, ecsc00a02a05.epam.com, executor 1, partition 47, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:05,950] {bash_operator.py:123} INFO - 19/01/29 18:53:05 INFO scheduler.TaskSetManager: Finished task 45.0 in stage 2.0 (TID 48) in 600 ms on ecsc00a02a05.epam.com (executor 1) (45/200)
[2019-01-29 18:53:06,034] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 48.0 in stage 2.0 (TID 51, ecsc00a02a05.epam.com, executor 1, partition 48, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,034] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 47.0 in stage 2.0 (TID 50) in 83 ms on ecsc00a02a05.epam.com (executor 1) (46/200)
[2019-01-29 18:53:06,077] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 49.0 in stage 2.0 (TID 52, ecsc00a022c7.epam.com, executor 2, partition 49, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,079] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 46.0 in stage 2.0 (TID 49) in 210 ms on ecsc00a022c7.epam.com (executor 2) (47/200)
[2019-01-29 18:53:06,116] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 50.0 in stage 2.0 (TID 53, ecsc00a02a05.epam.com, executor 1, partition 50, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,129] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 48.0 in stage 2.0 (TID 51) in 98 ms on ecsc00a02a05.epam.com (executor 1) (48/200)
[2019-01-29 18:53:06,178] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 51.0 in stage 2.0 (TID 54, ecsc00a022c7.epam.com, executor 2, partition 51, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,181] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 49.0 in stage 2.0 (TID 52) in 104 ms on ecsc00a022c7.epam.com (executor 2) (49/200)
[2019-01-29 18:53:06,248] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 52.0 in stage 2.0 (TID 55, ecsc00a02a05.epam.com, executor 1, partition 52, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,248] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 50.0 in stage 2.0 (TID 53) in 133 ms on ecsc00a02a05.epam.com (executor 1) (50/200)
[2019-01-29 18:53:06,295] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 53.0 in stage 2.0 (TID 56, ecsc00a022c7.epam.com, executor 2, partition 53, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,298] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 51.0 in stage 2.0 (TID 54) in 120 ms on ecsc00a022c7.epam.com (executor 2) (51/200)
[2019-01-29 18:53:06,383] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 54.0 in stage 2.0 (TID 57, ecsc00a02a05.epam.com, executor 1, partition 54, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,384] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 52.0 in stage 2.0 (TID 55) in 128 ms on ecsc00a02a05.epam.com (executor 1) (52/200)
[2019-01-29 18:53:06,395] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 55.0 in stage 2.0 (TID 58, ecsc00a022c7.epam.com, executor 2, partition 55, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,395] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 53.0 in stage 2.0 (TID 56) in 101 ms on ecsc00a022c7.epam.com (executor 2) (53/200)
[2019-01-29 18:53:06,468] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 56.0 in stage 2.0 (TID 59, ecsc00a02a05.epam.com, executor 1, partition 56, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,468] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 54.0 in stage 2.0 (TID 57) in 95 ms on ecsc00a02a05.epam.com (executor 1) (54/200)
[2019-01-29 18:53:06,488] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 57.0 in stage 2.0 (TID 60, ecsc00a022c7.epam.com, executor 2, partition 57, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,490] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 55.0 in stage 2.0 (TID 58) in 98 ms on ecsc00a022c7.epam.com (executor 2) (55/200)
[2019-01-29 18:53:06,586] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 58.0 in stage 2.0 (TID 61, ecsc00a02a05.epam.com, executor 1, partition 58, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,586] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 56.0 in stage 2.0 (TID 59) in 127 ms on ecsc00a02a05.epam.com (executor 1) (56/200)
[2019-01-29 18:53:06,699] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO spark.ExecutorAllocationManager: Requesting 15 new executors because tasks are backlogged (new desired total will be 144)
[2019-01-29 18:53:06,718] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 59.0 in stage 2.0 (TID 62, ecsc00a02a05.epam.com, executor 1, partition 59, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,719] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 58.0 in stage 2.0 (TID 61) in 134 ms on ecsc00a02a05.epam.com (executor 1) (57/200)
[2019-01-29 18:53:06,785] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 60.0 in stage 2.0 (TID 63, ecsc00a02a05.epam.com, executor 1, partition 60, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,785] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 59.0 in stage 2.0 (TID 62) in 63 ms on ecsc00a02a05.epam.com (executor 1) (58/200)
[2019-01-29 18:53:06,906] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 61.0 in stage 2.0 (TID 64, ecsc00a02a05.epam.com, executor 1, partition 61, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,917] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 60.0 in stage 2.0 (TID 63) in 127 ms on ecsc00a02a05.epam.com (executor 1) (59/200)
[2019-01-29 18:53:06,988] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Starting task 62.0 in stage 2.0 (TID 65, ecsc00a022c7.epam.com, executor 2, partition 62, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:06,988] {bash_operator.py:123} INFO - 19/01/29 18:53:06 INFO scheduler.TaskSetManager: Finished task 57.0 in stage 2.0 (TID 60) in 501 ms on ecsc00a022c7.epam.com (executor 2) (60/200)
[2019-01-29 18:53:07,070] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 63.0 in stage 2.0 (TID 66, ecsc00a02a05.epam.com, executor 1, partition 63, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,070] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 61.0 in stage 2.0 (TID 64) in 165 ms on ecsc00a02a05.epam.com (executor 1) (61/200)
[2019-01-29 18:53:07,114] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 64.0 in stage 2.0 (TID 67, ecsc00a022c7.epam.com, executor 2, partition 64, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,114] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 62.0 in stage 2.0 (TID 65) in 130 ms on ecsc00a022c7.epam.com (executor 2) (62/200)
[2019-01-29 18:53:07,189] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 65.0 in stage 2.0 (TID 68, ecsc00a022c7.epam.com, executor 2, partition 65, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,189] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 64.0 in stage 2.0 (TID 67) in 77 ms on ecsc00a022c7.epam.com (executor 2) (63/200)
[2019-01-29 18:53:07,228] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 66.0 in stage 2.0 (TID 69, ecsc00a02a05.epam.com, executor 1, partition 66, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,229] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 63.0 in stage 2.0 (TID 66) in 153 ms on ecsc00a02a05.epam.com (executor 1) (64/200)
[2019-01-29 18:53:07,376] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 67.0 in stage 2.0 (TID 70, ecsc00a022c7.epam.com, executor 2, partition 67, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,376] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 65.0 in stage 2.0 (TID 68) in 188 ms on ecsc00a022c7.epam.com (executor 2) (65/200)
[2019-01-29 18:53:07,389] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 68.0 in stage 2.0 (TID 71, ecsc00a02a05.epam.com, executor 1, partition 68, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,389] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 66.0 in stage 2.0 (TID 69) in 170 ms on ecsc00a02a05.epam.com (executor 1) (66/200)
[2019-01-29 18:53:07,410] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 69.0 in stage 2.0 (TID 72, ECSC00A02A04.epam.com, executor 3, partition 69, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,410] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 35.0 in stage 2.0 (TID 38) in 4169 ms on ECSC00A02A04.epam.com (executor 3) (67/200)
[2019-01-29 18:53:07,496] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 70.0 in stage 2.0 (TID 73, ecsc00a022c7.epam.com, executor 2, partition 70, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,497] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 67.0 in stage 2.0 (TID 70) in 121 ms on ecsc00a022c7.epam.com (executor 2) (68/200)
[2019-01-29 18:53:07,563] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 71.0 in stage 2.0 (TID 74, ecsc00a02a05.epam.com, executor 1, partition 71, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,565] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 68.0 in stage 2.0 (TID 71) in 176 ms on ecsc00a02a05.epam.com (executor 1) (69/200)
[2019-01-29 18:53:07,625] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 72.0 in stage 2.0 (TID 75, ecsc00a022c7.epam.com, executor 2, partition 72, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,626] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 70.0 in stage 2.0 (TID 73) in 134 ms on ecsc00a022c7.epam.com (executor 2) (70/200)
[2019-01-29 18:53:07,637] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 73.0 in stage 2.0 (TID 76, ECSC00A02A04.epam.com, executor 3, partition 73, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,637] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 69.0 in stage 2.0 (TID 72) in 232 ms on ECSC00A02A04.epam.com (executor 3) (71/200)
[2019-01-29 18:53:07,680] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 74.0 in stage 2.0 (TID 77, ecsc00a02a05.epam.com, executor 1, partition 74, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,680] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 71.0 in stage 2.0 (TID 74) in 128 ms on ecsc00a02a05.epam.com (executor 1) (72/200)
[2019-01-29 18:53:07,696] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 75.0 in stage 2.0 (TID 78, ecsc00a022c7.epam.com, executor 2, partition 75, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,700] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 72.0 in stage 2.0 (TID 75) in 75 ms on ecsc00a022c7.epam.com (executor 2) (73/200)
[2019-01-29 18:53:07,719] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 76.0 in stage 2.0 (TID 79, ecsc00a02339.epam.com, executor 4, partition 76, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,719] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 39.0 in stage 2.0 (TID 42) in 3718 ms on ecsc00a02339.epam.com (executor 4) (74/200)
[2019-01-29 18:53:07,751] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 77.0 in stage 2.0 (TID 80, ECSC00A02A04.epam.com, executor 3, partition 77, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,751] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 73.0 in stage 2.0 (TID 76) in 120 ms on ECSC00A02A04.epam.com (executor 3) (75/200)
[2019-01-29 18:53:07,813] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 78.0 in stage 2.0 (TID 81, ecsc00a022c7.epam.com, executor 2, partition 78, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,813] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 75.0 in stage 2.0 (TID 78) in 117 ms on ecsc00a022c7.epam.com (executor 2) (76/200)
[2019-01-29 18:53:07,886] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 79.0 in stage 2.0 (TID 82, ecsc00a02a05.epam.com, executor 1, partition 79, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,887] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 80.0 in stage 2.0 (TID 83, ECSC00A02A04.epam.com, executor 3, partition 80, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,887] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 74.0 in stage 2.0 (TID 77) in 210 ms on ecsc00a02a05.epam.com (executor 1) (77/200)
[2019-01-29 18:53:07,887] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 77.0 in stage 2.0 (TID 80) in 138 ms on ECSC00A02A04.epam.com (executor 3) (78/200)
[2019-01-29 18:53:07,931] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 81.0 in stage 2.0 (TID 84, ecsc00a02339.epam.com, executor 4, partition 81, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,932] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 76.0 in stage 2.0 (TID 79) in 218 ms on ecsc00a02339.epam.com (executor 4) (79/200)
[2019-01-29 18:53:07,979] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 82.0 in stage 2.0 (TID 85, ecsc00a022c7.epam.com, executor 2, partition 82, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,981] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Finished task 78.0 in stage 2.0 (TID 81) in 169 ms on ecsc00a022c7.epam.com (executor 2) (80/200)
[2019-01-29 18:53:07,996] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 83.0 in stage 2.0 (TID 86, ECSC00A02A04.epam.com, executor 3, partition 83, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:07,996] {bash_operator.py:123} INFO - 19/01/29 18:53:07 INFO scheduler.TaskSetManager: Starting task 84.0 in stage 2.0 (TID 87, ecsc00a02a05.epam.com, executor 1, partition 84, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,005] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 80.0 in stage 2.0 (TID 83) in 116 ms on ECSC00A02A04.epam.com (executor 3) (81/200)
[2019-01-29 18:53:08,005] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 79.0 in stage 2.0 (TID 82) in 117 ms on ecsc00a02a05.epam.com (executor 1) (82/200)
[2019-01-29 18:53:08,104] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 85.0 in stage 2.0 (TID 88, ecsc00a02a05.epam.com, executor 1, partition 85, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,104] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 84.0 in stage 2.0 (TID 87) in 108 ms on ecsc00a02a05.epam.com (executor 1) (83/200)
[2019-01-29 18:53:08,104] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 86.0 in stage 2.0 (TID 89, ecsc00a022c7.epam.com, executor 2, partition 86, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,108] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 82.0 in stage 2.0 (TID 85) in 128 ms on ecsc00a022c7.epam.com (executor 2) (84/200)
[2019-01-29 18:53:08,123] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 88.0 in stage 2.0 (TID 90, ecsc00a02339.epam.com, executor 4, partition 88, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,123] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 81.0 in stage 2.0 (TID 84) in 189 ms on ecsc00a02339.epam.com (executor 4) (85/200)
[2019-01-29 18:53:08,163] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 89.0 in stage 2.0 (TID 91, ECSC00A02A04.epam.com, executor 3, partition 89, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,170] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 83.0 in stage 2.0 (TID 86) in 173 ms on ECSC00A02A04.epam.com (executor 3) (86/200)
[2019-01-29 18:53:08,244] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 90.0 in stage 2.0 (TID 92, ecsc00a022c7.epam.com, executor 2, partition 90, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,245] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 91.0 in stage 2.0 (TID 93, ecsc00a02339.epam.com, executor 4, partition 91, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,245] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 86.0 in stage 2.0 (TID 89) in 141 ms on ecsc00a022c7.epam.com (executor 2) (87/200)
[2019-01-29 18:53:08,245] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 88.0 in stage 2.0 (TID 90) in 128 ms on ecsc00a02339.epam.com (executor 4) (88/200)
[2019-01-29 18:53:08,267] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 92.0 in stage 2.0 (TID 94, ecsc00a02a05.epam.com, executor 1, partition 92, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,273] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 85.0 in stage 2.0 (TID 88) in 169 ms on ecsc00a02a05.epam.com (executor 1) (89/200)
[2019-01-29 18:53:08,277] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 93.0 in stage 2.0 (TID 95, ECSC00A02A04.epam.com, executor 3, partition 93, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,284] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 89.0 in stage 2.0 (TID 91) in 122 ms on ECSC00A02A04.epam.com (executor 3) (90/200)
[2019-01-29 18:53:08,349] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 94.0 in stage 2.0 (TID 96, ecsc00a022c7.epam.com, executor 2, partition 94, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,352] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 90.0 in stage 2.0 (TID 92) in 108 ms on ecsc00a022c7.epam.com (executor 2) (91/200)
[2019-01-29 18:53:08,355] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 95.0 in stage 2.0 (TID 97, ecsc00a02339.epam.com, executor 4, partition 95, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,356] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 91.0 in stage 2.0 (TID 93) in 112 ms on ecsc00a02339.epam.com (executor 4) (92/200)
[2019-01-29 18:53:08,357] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 96.0 in stage 2.0 (TID 98, ECSC00A02A04.epam.com, executor 3, partition 96, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,360] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 93.0 in stage 2.0 (TID 95) in 81 ms on ECSC00A02A04.epam.com (executor 3) (93/200)
[2019-01-29 18:53:08,372] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 97.0 in stage 2.0 (TID 99, ecsc00a02a05.epam.com, executor 1, partition 97, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,372] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 92.0 in stage 2.0 (TID 94) in 106 ms on ecsc00a02a05.epam.com (executor 1) (94/200)
[2019-01-29 18:53:08,422] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 98.0 in stage 2.0 (TID 100, ecsc00a02339.epam.com, executor 4, partition 98, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,430] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 99.0 in stage 2.0 (TID 101, ecsc00a022c7.epam.com, executor 2, partition 99, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,430] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 94.0 in stage 2.0 (TID 96) in 80 ms on ecsc00a022c7.epam.com (executor 2) (95/200)
[2019-01-29 18:53:08,433] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 95.0 in stage 2.0 (TID 97) in 78 ms on ecsc00a02339.epam.com (executor 4) (96/200)
[2019-01-29 18:53:08,455] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 100.0 in stage 2.0 (TID 102, ECSC00A02A04.epam.com, executor 3, partition 100, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,456] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 96.0 in stage 2.0 (TID 98) in 88 ms on ECSC00A02A04.epam.com (executor 3) (97/200)
[2019-01-29 18:53:08,473] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 101.0 in stage 2.0 (TID 103, ecsc00a02a05.epam.com, executor 1, partition 101, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,473] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 97.0 in stage 2.0 (TID 99) in 100 ms on ecsc00a02a05.epam.com (executor 1) (98/200)
[2019-01-29 18:53:08,595] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 102.0 in stage 2.0 (TID 104, ecsc00a02339.epam.com, executor 4, partition 102, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,599] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 98.0 in stage 2.0 (TID 100) in 176 ms on ecsc00a02339.epam.com (executor 4) (99/200)
[2019-01-29 18:53:08,619] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 103.0 in stage 2.0 (TID 105, ECSC00A02A04.epam.com, executor 3, partition 103, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,620] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 104.0 in stage 2.0 (TID 106, ecsc00a02a05.epam.com, executor 1, partition 104, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,620] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 100.0 in stage 2.0 (TID 102) in 173 ms on ECSC00A02A04.epam.com (executor 3) (100/200)
[2019-01-29 18:53:08,620] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 101.0 in stage 2.0 (TID 103) in 148 ms on ecsc00a02a05.epam.com (executor 1) (101/200)
[2019-01-29 18:53:08,623] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 105.0 in stage 2.0 (TID 107, ecsc00a022c7.epam.com, executor 2, partition 105, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,636] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 99.0 in stage 2.0 (TID 101) in 197 ms on ecsc00a022c7.epam.com (executor 2) (102/200)
[2019-01-29 18:53:08,687] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 106.0 in stage 2.0 (TID 108, ecsc00a02339.epam.com, executor 4, partition 106, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,687] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 102.0 in stage 2.0 (TID 104) in 93 ms on ecsc00a02339.epam.com (executor 4) (103/200)
[2019-01-29 18:53:08,715] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 107.0 in stage 2.0 (TID 109, ECSC00A02A04.epam.com, executor 3, partition 107, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,716] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 103.0 in stage 2.0 (TID 105) in 98 ms on ECSC00A02A04.epam.com (executor 3) (104/200)
[2019-01-29 18:53:08,773] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 108.0 in stage 2.0 (TID 110, ecsc00a022c7.epam.com, executor 2, partition 108, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,794] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 105.0 in stage 2.0 (TID 107) in 153 ms on ecsc00a022c7.epam.com (executor 2) (105/200)
[2019-01-29 18:53:08,794] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 109.0 in stage 2.0 (TID 111, ecsc00a02a05.epam.com, executor 1, partition 109, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,794] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 104.0 in stage 2.0 (TID 106) in 176 ms on ecsc00a02a05.epam.com (executor 1) (106/200)
[2019-01-29 18:53:08,798] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 110.0 in stage 2.0 (TID 112, ecsc00a02339.epam.com, executor 4, partition 110, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,799] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 106.0 in stage 2.0 (TID 108) in 112 ms on ecsc00a02339.epam.com (executor 4) (107/200)
[2019-01-29 18:53:08,882] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 111.0 in stage 2.0 (TID 113, ECSC00A02A04.epam.com, executor 3, partition 111, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,882] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 107.0 in stage 2.0 (TID 109) in 167 ms on ECSC00A02A04.epam.com (executor 3) (108/200)
[2019-01-29 18:53:08,884] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 112.0 in stage 2.0 (TID 114, ecsc00a022c7.epam.com, executor 2, partition 112, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,895] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 108.0 in stage 2.0 (TID 110) in 117 ms on ecsc00a022c7.epam.com (executor 2) (109/200)
[2019-01-29 18:53:08,910] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Starting task 113.0 in stage 2.0 (TID 115, ecsc00a02339.epam.com, executor 4, partition 113, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:08,917] {bash_operator.py:123} INFO - 19/01/29 18:53:08 INFO scheduler.TaskSetManager: Finished task 110.0 in stage 2.0 (TID 112) in 119 ms on ecsc00a02339.epam.com (executor 4) (110/200)
[2019-01-29 18:53:09,002] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 114.0 in stage 2.0 (TID 116, ecsc00a022c7.epam.com, executor 2, partition 114, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,002] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 112.0 in stage 2.0 (TID 114) in 118 ms on ecsc00a022c7.epam.com (executor 2) (111/200)
[2019-01-29 18:53:09,002] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 115.0 in stage 2.0 (TID 117, ecsc00a02339.epam.com, executor 4, partition 115, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,002] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 113.0 in stage 2.0 (TID 115) in 91 ms on ecsc00a02339.epam.com (executor 4) (112/200)
[2019-01-29 18:53:09,069] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 116.0 in stage 2.0 (TID 118, ecsc00a022c7.epam.com, executor 2, partition 116, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,069] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 117.0 in stage 2.0 (TID 119, ecsc00a02a05.epam.com, executor 1, partition 117, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,069] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 114.0 in stage 2.0 (TID 116) in 68 ms on ecsc00a022c7.epam.com (executor 2) (113/200)
[2019-01-29 18:53:09,069] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 109.0 in stage 2.0 (TID 111) in 276 ms on ecsc00a02a05.epam.com (executor 1) (114/200)
[2019-01-29 18:53:09,082] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 118.0 in stage 2.0 (TID 120, ECSC00A02A04.epam.com, executor 3, partition 118, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,083] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 111.0 in stage 2.0 (TID 113) in 203 ms on ECSC00A02A04.epam.com (executor 3) (115/200)
[2019-01-29 18:53:09,132] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 119.0 in stage 2.0 (TID 121, ecsc00a02339.epam.com, executor 4, partition 119, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,132] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 115.0 in stage 2.0 (TID 117) in 131 ms on ecsc00a02339.epam.com (executor 4) (116/200)
[2019-01-29 18:53:09,153] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 120.0 in stage 2.0 (TID 122, ecsc00a022c7.epam.com, executor 2, partition 120, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,154] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 116.0 in stage 2.0 (TID 118) in 84 ms on ecsc00a022c7.epam.com (executor 2) (117/200)
[2019-01-29 18:53:09,210] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 121.0 in stage 2.0 (TID 123, ECSC00A02A04.epam.com, executor 3, partition 121, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,210] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 118.0 in stage 2.0 (TID 120) in 129 ms on ECSC00A02A04.epam.com (executor 3) (118/200)
[2019-01-29 18:53:09,226] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 122.0 in stage 2.0 (TID 124, ecsc00a022c7.epam.com, executor 2, partition 122, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,226] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 120.0 in stage 2.0 (TID 122) in 76 ms on ecsc00a022c7.epam.com (executor 2) (119/200)
[2019-01-29 18:53:09,242] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 123.0 in stage 2.0 (TID 125, ecsc00a02339.epam.com, executor 4, partition 123, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,242] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 119.0 in stage 2.0 (TID 121) in 111 ms on ecsc00a02339.epam.com (executor 4) (120/200)
[2019-01-29 18:53:09,277] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 124.0 in stage 2.0 (TID 126, ecsc00a02a05.epam.com, executor 1, partition 124, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,277] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 117.0 in stage 2.0 (TID 119) in 210 ms on ecsc00a02a05.epam.com (executor 1) (121/200)
[2019-01-29 18:53:09,290] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 125.0 in stage 2.0 (TID 127, ecsc00a022c7.epam.com, executor 2, partition 125, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,291] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 122.0 in stage 2.0 (TID 124) in 65 ms on ecsc00a022c7.epam.com (executor 2) (122/200)
[2019-01-29 18:53:09,456] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 126.0 in stage 2.0 (TID 128, ecsc00a022c7.epam.com, executor 2, partition 126, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,456] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 125.0 in stage 2.0 (TID 127) in 166 ms on ecsc00a022c7.epam.com (executor 2) (123/200)
[2019-01-29 18:53:09,488] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 127.0 in stage 2.0 (TID 129, ecsc00a02a05.epam.com, executor 1, partition 127, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,488] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 124.0 in stage 2.0 (TID 126) in 211 ms on ecsc00a02a05.epam.com (executor 1) (124/200)
[2019-01-29 18:53:09,493] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 128.0 in stage 2.0 (TID 130, ECSC00A02A04.epam.com, executor 3, partition 128, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,498] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 121.0 in stage 2.0 (TID 123) in 301 ms on ECSC00A02A04.epam.com (executor 3) (125/200)
[2019-01-29 18:53:09,505] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 129.0 in stage 2.0 (TID 131, ecsc00a02339.epam.com, executor 4, partition 129, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,510] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 123.0 in stage 2.0 (TID 125) in 266 ms on ecsc00a02339.epam.com (executor 4) (126/200)
[2019-01-29 18:53:09,575] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 130.0 in stage 2.0 (TID 132, ecsc00a022c7.epam.com, executor 2, partition 130, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,576] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 126.0 in stage 2.0 (TID 128) in 121 ms on ecsc00a022c7.epam.com (executor 2) (127/200)
[2019-01-29 18:53:09,610] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 131.0 in stage 2.0 (TID 133, ecsc00a02339.epam.com, executor 4, partition 131, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,610] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 129.0 in stage 2.0 (TID 131) in 106 ms on ecsc00a02339.epam.com (executor 4) (128/200)
[2019-01-29 18:53:09,641] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 132.0 in stage 2.0 (TID 134, ECSC00A02A04.epam.com, executor 3, partition 132, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,647] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 133.0 in stage 2.0 (TID 135, ecsc00a022c7.epam.com, executor 2, partition 133, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,650] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 128.0 in stage 2.0 (TID 130) in 157 ms on ECSC00A02A04.epam.com (executor 3) (129/200)
[2019-01-29 18:53:09,651] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 130.0 in stage 2.0 (TID 132) in 78 ms on ecsc00a022c7.epam.com (executor 2) (130/200)
[2019-01-29 18:53:09,680] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 134.0 in stage 2.0 (TID 136, ecsc00a02a05.epam.com, executor 1, partition 134, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,680] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 127.0 in stage 2.0 (TID 129) in 196 ms on ecsc00a02a05.epam.com (executor 1) (131/200)
[2019-01-29 18:53:09,716] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 135.0 in stage 2.0 (TID 137, ECSC00A02A04.epam.com, executor 3, partition 135, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,717] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 132.0 in stage 2.0 (TID 134) in 76 ms on ECSC00A02A04.epam.com (executor 3) (132/200)
[2019-01-29 18:53:09,780] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 136.0 in stage 2.0 (TID 138, ecsc00a022c7.epam.com, executor 2, partition 136, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,780] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 133.0 in stage 2.0 (TID 135) in 131 ms on ecsc00a022c7.epam.com (executor 2) (133/200)
[2019-01-29 18:53:09,785] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 137.0 in stage 2.0 (TID 139, ECSC00A02A04.epam.com, executor 3, partition 137, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,785] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 135.0 in stage 2.0 (TID 137) in 69 ms on ECSC00A02A04.epam.com (executor 3) (134/200)
[2019-01-29 18:53:09,788] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 138.0 in stage 2.0 (TID 140, ecsc00a02339.epam.com, executor 4, partition 138, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,788] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 131.0 in stage 2.0 (TID 133) in 179 ms on ecsc00a02339.epam.com (executor 4) (135/200)
[2019-01-29 18:53:09,828] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 139.0 in stage 2.0 (TID 141, ecsc00a02a05.epam.com, executor 1, partition 139, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,828] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 134.0 in stage 2.0 (TID 136) in 150 ms on ecsc00a02a05.epam.com (executor 1) (136/200)
[2019-01-29 18:53:09,855] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 140.0 in stage 2.0 (TID 142, ecsc00a022c7.epam.com, executor 2, partition 140, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,856] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 136.0 in stage 2.0 (TID 138) in 83 ms on ecsc00a022c7.epam.com (executor 2) (137/200)
[2019-01-29 18:53:09,859] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 141.0 in stage 2.0 (TID 143, ECSC00A02A04.epam.com, executor 3, partition 141, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,859] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 137.0 in stage 2.0 (TID 139) in 76 ms on ECSC00A02A04.epam.com (executor 3) (138/200)
[2019-01-29 18:53:09,913] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 142.0 in stage 2.0 (TID 144, ecsc00a02339.epam.com, executor 4, partition 142, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,913] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 138.0 in stage 2.0 (TID 140) in 125 ms on ecsc00a02339.epam.com (executor 4) (139/200)
[2019-01-29 18:53:09,927] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 143.0 in stage 2.0 (TID 145, ecsc00a022c7.epam.com, executor 2, partition 143, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,927] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 140.0 in stage 2.0 (TID 142) in 74 ms on ecsc00a022c7.epam.com (executor 2) (140/200)
[2019-01-29 18:53:09,944] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Starting task 144.0 in stage 2.0 (TID 146, ecsc00a02a05.epam.com, executor 1, partition 144, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:09,945] {bash_operator.py:123} INFO - 19/01/29 18:53:09 INFO scheduler.TaskSetManager: Finished task 139.0 in stage 2.0 (TID 141) in 118 ms on ecsc00a02a05.epam.com (executor 1) (141/200)
[2019-01-29 18:53:10,029] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 145.0 in stage 2.0 (TID 147, ecsc00a02339.epam.com, executor 4, partition 145, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,029] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 142.0 in stage 2.0 (TID 144) in 118 ms on ecsc00a02339.epam.com (executor 4) (142/200)
[2019-01-29 18:53:10,074] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 146.0 in stage 2.0 (TID 148, ecsc00a02a05.epam.com, executor 1, partition 146, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,074] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 144.0 in stage 2.0 (TID 146) in 129 ms on ecsc00a02a05.epam.com (executor 1) (143/200)
[2019-01-29 18:53:10,098] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 147.0 in stage 2.0 (TID 149, ecsc00a02339.epam.com, executor 4, partition 147, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,098] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 145.0 in stage 2.0 (TID 147) in 69 ms on ecsc00a02339.epam.com (executor 4) (144/200)
[2019-01-29 18:53:10,145] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 148.0 in stage 2.0 (TID 150, ecsc00a02a05.epam.com, executor 1, partition 148, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,151] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 146.0 in stage 2.0 (TID 148) in 77 ms on ecsc00a02a05.epam.com (executor 1) (145/200)
[2019-01-29 18:53:10,165] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 149.0 in stage 2.0 (TID 151, ecsc00a02339.epam.com, executor 4, partition 149, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,165] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 147.0 in stage 2.0 (TID 149) in 70 ms on ecsc00a02339.epam.com (executor 4) (146/200)
[2019-01-29 18:53:10,236] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 150.0 in stage 2.0 (TID 152, ecsc00a02339.epam.com, executor 4, partition 150, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,237] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 149.0 in stage 2.0 (TID 151) in 76 ms on ecsc00a02339.epam.com (executor 4) (147/200)
[2019-01-29 18:53:10,328] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 151.0 in stage 2.0 (TID 153, ecsc00a02a05.epam.com, executor 1, partition 151, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,342] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 148.0 in stage 2.0 (TID 150) in 188 ms on ecsc00a02a05.epam.com (executor 1) (148/200)
[2019-01-29 18:53:10,342] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 152.0 in stage 2.0 (TID 154, ecsc00a02339.epam.com, executor 4, partition 152, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,343] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 150.0 in stage 2.0 (TID 152) in 98 ms on ecsc00a02339.epam.com (executor 4) (149/200)
[2019-01-29 18:53:10,343] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 153.0 in stage 2.0 (TID 155, ECSC00A02A04.epam.com, executor 3, partition 153, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,343] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 141.0 in stage 2.0 (TID 143) in 479 ms on ECSC00A02A04.epam.com (executor 3) (150/200)
[2019-01-29 18:53:10,393] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 154.0 in stage 2.0 (TID 156, ecsc00a02339.epam.com, executor 4, partition 154, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,399] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 155.0 in stage 2.0 (TID 157, ecsc00a022c7.epam.com, executor 2, partition 155, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,399] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 152.0 in stage 2.0 (TID 154) in 62 ms on ecsc00a02339.epam.com (executor 4) (151/200)
[2019-01-29 18:53:10,399] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 143.0 in stage 2.0 (TID 145) in 469 ms on ecsc00a022c7.epam.com (executor 2) (152/200)
[2019-01-29 18:53:10,446] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 156.0 in stage 2.0 (TID 158, ECSC00A02A04.epam.com, executor 3, partition 156, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,457] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 153.0 in stage 2.0 (TID 155) in 110 ms on ECSC00A02A04.epam.com (executor 3) (153/200)
[2019-01-29 18:53:10,457] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 157.0 in stage 2.0 (TID 159, ecsc00a02a05.epam.com, executor 1, partition 157, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,457] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 151.0 in stage 2.0 (TID 153) in 128 ms on ecsc00a02a05.epam.com (executor 1) (154/200)
[2019-01-29 18:53:10,482] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 158.0 in stage 2.0 (TID 160, ecsc00a02339.epam.com, executor 4, partition 158, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,482] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 154.0 in stage 2.0 (TID 156) in 90 ms on ecsc00a02339.epam.com (executor 4) (155/200)
[2019-01-29 18:53:10,528] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 159.0 in stage 2.0 (TID 161, ecsc00a022c7.epam.com, executor 2, partition 159, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,534] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 155.0 in stage 2.0 (TID 157) in 136 ms on ecsc00a022c7.epam.com (executor 2) (156/200)
[2019-01-29 18:53:10,561] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 160.0 in stage 2.0 (TID 162, ECSC00A02A04.epam.com, executor 3, partition 160, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,561] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 156.0 in stage 2.0 (TID 158) in 115 ms on ECSC00A02A04.epam.com (executor 3) (157/200)
[2019-01-29 18:53:10,584] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 161.0 in stage 2.0 (TID 163, ecsc00a02a05.epam.com, executor 1, partition 161, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,584] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 157.0 in stage 2.0 (TID 159) in 127 ms on ecsc00a02a05.epam.com (executor 1) (158/200)
[2019-01-29 18:53:10,621] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 162.0 in stage 2.0 (TID 164, ecsc00a022c7.epam.com, executor 2, partition 162, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,621] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 159.0 in stage 2.0 (TID 161) in 94 ms on ecsc00a022c7.epam.com (executor 2) (159/200)
[2019-01-29 18:53:10,642] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 163.0 in stage 2.0 (TID 165, ECSC00A02A04.epam.com, executor 3, partition 163, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,642] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 160.0 in stage 2.0 (TID 162) in 83 ms on ECSC00A02A04.epam.com (executor 3) (160/200)
[2019-01-29 18:53:10,663] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 164.0 in stage 2.0 (TID 166, ecsc00a02a05.epam.com, executor 1, partition 164, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,663] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 161.0 in stage 2.0 (TID 163) in 81 ms on ecsc00a02a05.epam.com (executor 1) (161/200)
[2019-01-29 18:53:10,694] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 165.0 in stage 2.0 (TID 167, ecsc00a022c7.epam.com, executor 2, partition 165, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,694] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 162.0 in stage 2.0 (TID 164) in 74 ms on ecsc00a022c7.epam.com (executor 2) (162/200)
[2019-01-29 18:53:10,733] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 166.0 in stage 2.0 (TID 168, ECSC00A02A04.epam.com, executor 3, partition 166, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,733] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 163.0 in stage 2.0 (TID 165) in 91 ms on ECSC00A02A04.epam.com (executor 3) (163/200)
[2019-01-29 18:53:10,737] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 167.0 in stage 2.0 (TID 169, ecsc00a02a05.epam.com, executor 1, partition 167, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,737] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 164.0 in stage 2.0 (TID 166) in 75 ms on ecsc00a02a05.epam.com (executor 1) (164/200)
[2019-01-29 18:53:10,760] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 168.0 in stage 2.0 (TID 170, ecsc00a022c7.epam.com, executor 2, partition 168, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,760] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 165.0 in stage 2.0 (TID 167) in 65 ms on ecsc00a022c7.epam.com (executor 2) (165/200)
[2019-01-29 18:53:10,805] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 169.0 in stage 2.0 (TID 171, ecsc00a02a05.epam.com, executor 1, partition 169, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,807] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 167.0 in stage 2.0 (TID 169) in 71 ms on ecsc00a02a05.epam.com (executor 1) (166/200)
[2019-01-29 18:53:10,809] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 170.0 in stage 2.0 (TID 172, ECSC00A02A04.epam.com, executor 3, partition 170, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,809] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 166.0 in stage 2.0 (TID 168) in 78 ms on ECSC00A02A04.epam.com (executor 3) (167/200)
[2019-01-29 18:53:10,823] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 171.0 in stage 2.0 (TID 173, ecsc00a022c7.epam.com, executor 2, partition 171, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,824] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 168.0 in stage 2.0 (TID 170) in 65 ms on ecsc00a022c7.epam.com (executor 2) (168/200)
[2019-01-29 18:53:10,893] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 172.0 in stage 2.0 (TID 174, ecsc00a022c7.epam.com, executor 2, partition 172, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,893] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 171.0 in stage 2.0 (TID 173) in 71 ms on ecsc00a022c7.epam.com (executor 2) (169/200)
[2019-01-29 18:53:10,918] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 173.0 in stage 2.0 (TID 175, ecsc00a02a05.epam.com, executor 1, partition 173, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,918] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 169.0 in stage 2.0 (TID 171) in 114 ms on ecsc00a02a05.epam.com (executor 1) (170/200)
[2019-01-29 18:53:10,921] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 174.0 in stage 2.0 (TID 176, ECSC00A02A04.epam.com, executor 3, partition 174, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,930] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 170.0 in stage 2.0 (TID 172) in 122 ms on ECSC00A02A04.epam.com (executor 3) (171/200)
[2019-01-29 18:53:10,979] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 175.0 in stage 2.0 (TID 177, ecsc00a022c7.epam.com, executor 2, partition 175, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,979] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Starting task 176.0 in stage 2.0 (TID 178, ecsc00a02339.epam.com, executor 4, partition 176, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:10,981] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 172.0 in stage 2.0 (TID 174) in 88 ms on ecsc00a022c7.epam.com (executor 2) (172/200)
[2019-01-29 18:53:10,981] {bash_operator.py:123} INFO - 19/01/29 18:53:10 INFO scheduler.TaskSetManager: Finished task 158.0 in stage 2.0 (TID 160) in 499 ms on ecsc00a02339.epam.com (executor 4) (173/200)
[2019-01-29 18:53:11,041] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 177.0 in stage 2.0 (TID 179, ECSC00A02A04.epam.com, executor 3, partition 177, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,041] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 174.0 in stage 2.0 (TID 176) in 121 ms on ECSC00A02A04.epam.com (executor 3) (174/200)
[2019-01-29 18:53:11,050] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 178.0 in stage 2.0 (TID 180, ecsc00a022c7.epam.com, executor 2, partition 178, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,050] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 179.0 in stage 2.0 (TID 181, ecsc00a02339.epam.com, executor 4, partition 179, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,062] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 176.0 in stage 2.0 (TID 178) in 73 ms on ecsc00a02339.epam.com (executor 4) (175/200)
[2019-01-29 18:53:11,062] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 175.0 in stage 2.0 (TID 177) in 84 ms on ecsc00a022c7.epam.com (executor 2) (176/200)
[2019-01-29 18:53:11,072] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 180.0 in stage 2.0 (TID 182, ecsc00a02a05.epam.com, executor 1, partition 180, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,086] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 173.0 in stage 2.0 (TID 175) in 166 ms on ecsc00a02a05.epam.com (executor 1) (177/200)
[2019-01-29 18:53:11,120] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 181.0 in stage 2.0 (TID 183, ECSC00A02A04.epam.com, executor 3, partition 181, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,120] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 177.0 in stage 2.0 (TID 179) in 78 ms on ECSC00A02A04.epam.com (executor 3) (178/200)
[2019-01-29 18:53:11,161] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 182.0 in stage 2.0 (TID 184, ecsc00a022c7.epam.com, executor 2, partition 182, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,161] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 183.0 in stage 2.0 (TID 185, ecsc00a02339.epam.com, executor 4, partition 183, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,164] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 178.0 in stage 2.0 (TID 180) in 114 ms on ecsc00a022c7.epam.com (executor 2) (179/200)
[2019-01-29 18:53:11,165] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 179.0 in stage 2.0 (TID 181) in 115 ms on ecsc00a02339.epam.com (executor 4) (180/200)
[2019-01-29 18:53:11,166] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 184.0 in stage 2.0 (TID 186, ecsc00a02a05.epam.com, executor 1, partition 184, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,169] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 180.0 in stage 2.0 (TID 182) in 97 ms on ecsc00a02a05.epam.com (executor 1) (181/200)
[2019-01-29 18:53:11,225] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 185.0 in stage 2.0 (TID 187, ECSC00A02A04.epam.com, executor 3, partition 185, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,225] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 181.0 in stage 2.0 (TID 183) in 108 ms on ECSC00A02A04.epam.com (executor 3) (182/200)
[2019-01-29 18:53:11,309] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 186.0 in stage 2.0 (TID 188, ecsc00a02339.epam.com, executor 4, partition 186, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,309] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 187.0 in stage 2.0 (TID 189, ecsc00a022c7.epam.com, executor 2, partition 187, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,310] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 183.0 in stage 2.0 (TID 185) in 148 ms on ecsc00a02339.epam.com (executor 4) (183/200)
[2019-01-29 18:53:11,310] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 182.0 in stage 2.0 (TID 184) in 150 ms on ecsc00a022c7.epam.com (executor 2) (184/200)
[2019-01-29 18:53:11,311] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 188.0 in stage 2.0 (TID 190, ECSC00A02A04.epam.com, executor 3, partition 188, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,312] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 185.0 in stage 2.0 (TID 187) in 88 ms on ECSC00A02A04.epam.com (executor 3) (185/200)
[2019-01-29 18:53:11,326] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 189.0 in stage 2.0 (TID 191, ecsc00a02a05.epam.com, executor 1, partition 189, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,326] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 184.0 in stage 2.0 (TID 186) in 160 ms on ecsc00a02a05.epam.com (executor 1) (186/200)
[2019-01-29 18:53:11,404] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 190.0 in stage 2.0 (TID 192, ecsc00a02339.epam.com, executor 4, partition 190, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,415] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 186.0 in stage 2.0 (TID 188) in 108 ms on ecsc00a02339.epam.com (executor 4) (187/200)
[2019-01-29 18:53:11,448] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 191.0 in stage 2.0 (TID 193, ecsc00a02a05.epam.com, executor 1, partition 191, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,450] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 189.0 in stage 2.0 (TID 191) in 125 ms on ecsc00a02a05.epam.com (executor 1) (188/200)
[2019-01-29 18:53:11,464] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 192.0 in stage 2.0 (TID 194, ecsc00a02339.epam.com, executor 4, partition 192, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,473] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 190.0 in stage 2.0 (TID 192) in 69 ms on ecsc00a02339.epam.com (executor 4) (189/200)
[2019-01-29 18:53:11,544] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 193.0 in stage 2.0 (TID 195, ecsc00a02339.epam.com, executor 4, partition 193, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,544] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 192.0 in stage 2.0 (TID 194) in 80 ms on ecsc00a02339.epam.com (executor 4) (190/200)
[2019-01-29 18:53:11,613] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 194.0 in stage 2.0 (TID 196, ecsc00a02a05.epam.com, executor 1, partition 194, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,613] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 191.0 in stage 2.0 (TID 193) in 166 ms on ecsc00a02a05.epam.com (executor 1) (191/200)
[2019-01-29 18:53:11,679] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 195.0 in stage 2.0 (TID 197, ecsc00a02a05.epam.com, executor 1, partition 195, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,690] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 194.0 in stage 2.0 (TID 196) in 71 ms on ecsc00a02a05.epam.com (executor 1) (192/200)
[2019-01-29 18:53:11,757] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 196.0 in stage 2.0 (TID 198, ecsc00a02a05.epam.com, executor 1, partition 196, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,760] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 195.0 in stage 2.0 (TID 197) in 81 ms on ecsc00a02a05.epam.com (executor 1) (193/200)
[2019-01-29 18:53:11,779] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 197.0 in stage 2.0 (TID 199, ecsc00a022c7.epam.com, executor 2, partition 197, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,779] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 187.0 in stage 2.0 (TID 189) in 467 ms on ecsc00a022c7.epam.com (executor 2) (194/200)
[2019-01-29 18:53:11,795] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 198.0 in stage 2.0 (TID 200, ECSC00A02A04.epam.com, executor 3, partition 198, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,805] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 188.0 in stage 2.0 (TID 190) in 486 ms on ECSC00A02A04.epam.com (executor 3) (195/200)
[2019-01-29 18:53:11,842] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Starting task 199.0 in stage 2.0 (TID 201, ecsc00a022c7.epam.com, executor 2, partition 199, PROCESS_LOCAL, 4737 bytes)
[2019-01-29 18:53:11,843] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 197.0 in stage 2.0 (TID 199) in 69 ms on ecsc00a022c7.epam.com (executor 2) (196/200)
[2019-01-29 18:53:11,862] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 196.0 in stage 2.0 (TID 198) in 104 ms on ecsc00a02a05.epam.com (executor 1) (197/200)
[2019-01-29 18:53:11,862] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 198.0 in stage 2.0 (TID 200) in 68 ms on ECSC00A02A04.epam.com (executor 3) (198/200)
[2019-01-29 18:53:11,901] {bash_operator.py:123} INFO - 19/01/29 18:53:11 INFO scheduler.TaskSetManager: Finished task 199.0 in stage 2.0 (TID 201) in 60 ms on ecsc00a022c7.epam.com (executor 2) (199/200)
[2019-01-29 18:53:12,007] {bash_operator.py:123} INFO - 19/01/29 18:53:12 INFO scheduler.TaskSetManager: Finished task 193.0 in stage 2.0 (TID 195) in 465 ms on ecsc00a02339.epam.com (executor 4) (200/200)
[2019-01-29 18:53:12,008] {bash_operator.py:123} INFO - 19/01/29 18:53:12 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2019-01-29 18:53:12,018] {bash_operator.py:123} INFO - 19/01/29 18:53:12 INFO scheduler.DAGScheduler: ResultStage 2 (save at package.scala:26) finished in 14.646 s
[2019-01-29 18:53:12,018] {bash_operator.py:123} INFO - 19/01/29 18:53:12 INFO scheduler.DAGScheduler: Job 1 finished: save at package.scala:26, took 15.483572 s
[2019-01-29 18:53:13,725] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO datasources.FileFormatWriter: Job null committed.
[2019-01-29 18:53:13,772] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO server.AbstractConnector: Stopped Spark@204e90f7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
[2019-01-29 18:53:13,778] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO ui.SparkUI: Stopped Spark web UI at http://10.6.195.165:4040
[2019-01-29 18:53:13,821] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
[2019-01-29 18:53:13,826] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
[2019-01-29 18:53:13,827] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
[2019-01-29 18:53:13,840] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
[2019-01-29 18:53:13,840] {bash_operator.py:123} INFO - (serviceOption=None,
[2019-01-29 18:53:13,840] {bash_operator.py:123} INFO -  services=List(),
[2019-01-29 18:53:13,840] {bash_operator.py:123} INFO -  started=false)
[2019-01-29 18:53:13,843] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO cluster.YarnClientSchedulerBackend: Stopped
[2019-01-29 18:53:13,856] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2019-01-29 18:53:13,911] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO memory.MemoryStore: MemoryStore cleared
[2019-01-29 18:53:13,911] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO storage.BlockManager: BlockManager stopped
[2019-01-29 18:53:13,920] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
[2019-01-29 18:53:13,926] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2019-01-29 18:53:13,931] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO spark.SparkContext: Successfully stopped SparkContext
[2019-01-29 18:53:13,938] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO util.ShutdownHookManager: Shutdown hook called
[2019-01-29 18:53:13,940] {bash_operator.py:123} INFO - 19/01/29 18:53:13 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-d1a99f6c-04af-4a42-ba89-e790a9f6ab42
[2019-01-29 18:53:14,433] {bash_operator.py:127} INFO - Command exited with return code 0
[2019-01-29 18:53:16,212] {logging_mixin.py:95} INFO - [2019-01-29 18:53:16,211] {jobs.py:2527} INFO - Task exited with return code 0